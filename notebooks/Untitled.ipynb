{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aed2332f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-29 10:14:42.043542: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-29 10:14:42.353173: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-29 10:14:43.234604: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-29 10:14:43.234660: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-29 10:14:43.234666: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import random\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92ec6814",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniprot_rows = []\n",
    "\n",
    "with open(\"../data/raw/uniprot/swissprot.fasta\") as reader:\n",
    "    for line in reader:\n",
    "        if '>' not in line:\n",
    "            uniprot_rows.append({\"sequence\": line.strip('\\n'), \"class\": 0})\n",
    "        \n",
    "df_anticp_raw = pd.DataFrame(uniprot_rows, columns=[\"sequence\", \"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b4dcd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = keras.preprocessing.text.Tokenizer(char_level=True)\n",
    "tokenizer.fit_on_texts(['ACDEFGHIKLMNPQRSTVWY.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d50c360b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 20\n",
    "embed_dim = 16\n",
    "num_heads = 3\n",
    "ff_dim    = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4df93149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LYHEKYKVVEL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RKAVLLEEQGIEWKPEDTARPSGPREGGRRDGGRDG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>YAAIPLGAAIGALTSGQLAHSVRPGLIMLVSTVGSFLAVGLFAIMPV</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LLINKSPEERAALAEERTEGGTPLLIA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAVLVLIHAAVRRSDNLFLDEEAAAVTEASGLMSYPS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DRVMQELTEYELVPEAWGGDTIFAPISAKFGEGL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ILSRVGDGTQDNLSGCEK</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ELAKRWFT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ESEVLTPADEVFHLNKSDYTVPFVCGCRDLGEAAR</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GSDVAVNGSFPTIYRNYSNSVPYERRITTLLQWLDLPKAD</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          sequence  class\n",
       "0                                      LYHEKYKVVEL      0\n",
       "1             RKAVLLEEQGIEWKPEDTARPSGPREGGRRDGGRDG      0\n",
       "2  YAAIPLGAAIGALTSGQLAHSVRPGLIMLVSTVGSFLAVGLFAIMPV      0\n",
       "3                      LLINKSPEERAALAEERTEGGTPLLIA      0\n",
       "4            AAVLVLIHAAVRRSDNLFLDEEAAAVTEASGLMSYPS      0\n",
       "5               DRVMQELTEYELVPEAWGGDTIFAPISAKFGEGL      0\n",
       "6                               ILSRVGDGTQDNLSGCEK      0\n",
       "7                                         ELAKRWFT      0\n",
       "8              ESEVLTPADEVFHLNKSDYTVPFVCGCRDLGEAAR      0\n",
       "9         GSDVAVNGSFPTIYRNYSNSVPYERRITTLLQWLDLPKAD      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "anticp_rows = []\n",
    "\n",
    "with open(\"../data/raw/anti_cp/anticp2_alternate_internal_negative.txt\") as reader:\n",
    "    for line in reader:\n",
    "        anticp_rows.append({\"sequence\": line.strip('\\n'), \"class\": 0})\n",
    "\n",
    "        \n",
    "with open(\"../data/raw/anti_cp/anticp2_alternate_internal_positive.txt\") as reader:\n",
    "    for line in reader:\n",
    "        anticp_rows.append({\"sequence\": line.strip('\\n'), \"class\": 1})\n",
    "        \n",
    "with open(\"../data/raw/anti_cp/anticp2_alternate_validation_negative.txt\") as reader:\n",
    "    for line in reader:\n",
    "        anticp_rows.append({\"sequence\": line.strip('\\n'), \"class\": 0})\n",
    "\n",
    "        \n",
    "with open(\"../data/raw/anti_cp/anticp2_alternate_validation_positive.txt\") as reader:\n",
    "    for line in reader:\n",
    "        anticp_rows.append({\"sequence\": line.strip('\\n'), \"class\": 1})\n",
    "        \n",
    "'''\n",
    "for csv_file in glob.glob(\"../data/raw/tumorhope/*.csv\"):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    for r, row in df.iterrows():\n",
    "        anticp_rows.append({\"sequence\": row.Sequence, \"class\": 1})\n",
    "'''        \n",
    "df_anticp_raw = pd.DataFrame(anticp_rows, columns=[\"sequence\", \"class\"])\n",
    "df_anticp_raw.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72633c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1930</th>\n",
       "      <td>KRAKAAGGWSHWSPWSSC</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1931</th>\n",
       "      <td>AAKKWAKAKWAKAKKWAKAA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1932</th>\n",
       "      <td>FLPLIGRVLSGIL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1933</th>\n",
       "      <td>PAWFKARRWAWRMLKKAA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1934</th>\n",
       "      <td>KWKSFLKTFKSLKKTVLHTLLKLISS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1935</th>\n",
       "      <td>FAKKLAKKLAKLL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1936</th>\n",
       "      <td>FALALKALKK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1937</th>\n",
       "      <td>GLFAVIKKVASVIKGL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1938</th>\n",
       "      <td>ADRGWIKTLTKDCPNVISSICAGTIITACKNCA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1939</th>\n",
       "      <td>ESEFDRQEYEECKRQCMQLETSGQMRRCVSQCDKRFEEDIDWSKYDNQD</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sequence  class\n",
       "1930                                 KRAKAAGGWSHWSPWSSC      1\n",
       "1931                               AAKKWAKAKWAKAKKWAKAA      1\n",
       "1932                                      FLPLIGRVLSGIL      1\n",
       "1933                                 PAWFKARRWAWRMLKKAA      1\n",
       "1934                         KWKSFLKTFKSLKKTVLHTLLKLISS      1\n",
       "1935                                      FAKKLAKKLAKLL      1\n",
       "1936                                         FALALKALKK      1\n",
       "1937                                   GLFAVIKKVASVIKGL      1\n",
       "1938                  ADRGWIKTLTKDCPNVISSICAGTIITACKNCA      1\n",
       "1939  ESEFDRQEYEECKRQCMQLETSGQMRRCVSQCDKRFEEDIDWSKYDNQD      1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_anticp_raw.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d708f6a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1940, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_anticp_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5e4be7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_token = '.'\n",
    "max_len = 50\n",
    "\n",
    "X_anticp = []\n",
    "y_anticp = []\n",
    "\n",
    "for r, row in df_anticp_raw.iterrows():\n",
    "    X_anticp.append(row['sequence'])\n",
    "    y_anticp.append(float(row['class']))\n",
    "    \n",
    "    \n",
    "X_anticp = np.array(X_anticp).reshape((-1,1))\n",
    "y_anticp = np.array(y_anticp).reshape((-1,1))\n",
    "\n",
    "X_anticp, y_anticp = RandomUnderSampler().fit_resample(X_anticp, y_anticp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e798c1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_anticp = X_anticp[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fde0df76",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_anticp = y_anticp.reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc81c0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_anticp, y_anticp)\n",
    "\n",
    "tokenizer = keras.preprocessing.text.Tokenizer(char_level=True)\n",
    "tokenizer.fit_on_texts(['ACDEFGHIKLMNPQRSTVWY.'])\n",
    "\n",
    "X_train_tokens = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_tokens  = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "X_train_tokens_padded = keras.preprocessing.sequence.pad_sequences(X_train_tokens, maxlen=max_len)\n",
    "X_test_tokens_padded  = keras.preprocessing.sequence.pad_sequences(X_test_tokens, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f131bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1455, 50)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tokens_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a3fe595",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(vocab_size, input_length):\n",
    "\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(\n",
    "        keras.layers.Embedding(len(tokenizer.word_counts)+1, 20, input_length=50)\n",
    "    )\n",
    "    model.add(\n",
    "        keras.layers.Conv1D(512, 8)\n",
    "    )\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "    model.add(\n",
    "        keras.layers.Conv1D(256, 8)\n",
    "    )\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "    model.add(\n",
    "        keras.layers.Conv1D(128, 8)\n",
    "    )\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "    model.add(\n",
    "        keras.layers.Conv1D(64, 8)\n",
    "    )\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "    model.add(\n",
    "        keras.layers.Conv1D(32, 4)\n",
    "    )\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "    model.add(\n",
    "        keras.layers.Flatten()\n",
    "    )\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "    model.add(keras.layers.Dense(256, activation='relu'))\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "    model.add(keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "    model.add(keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "718ed543",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-29 10:14:49.000679: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-29 10:14:49.056349: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-11-29 10:14:49.056366: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-11-29 10:14:49.057150: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "182/182 [==============================] - 4s 20ms/step - loss: 0.7973 - acc: 0.5065 - val_loss: 0.6598 - val_acc: 0.5546\n",
      "Epoch 2/20\n",
      "182/182 [==============================] - 3s 19ms/step - loss: 0.7501 - acc: 0.5588 - val_loss: 0.5658 - val_acc: 0.7402\n",
      "Epoch 3/20\n",
      "182/182 [==============================] - 3s 19ms/step - loss: 0.6100 - acc: 0.6880 - val_loss: 0.4378 - val_acc: 0.8062\n",
      "Epoch 4/20\n",
      "182/182 [==============================] - 4s 20ms/step - loss: 0.5486 - acc: 0.7512 - val_loss: 0.3995 - val_acc: 0.8268\n",
      "Epoch 5/20\n",
      "182/182 [==============================] - 4s 20ms/step - loss: 0.5312 - acc: 0.7746 - val_loss: 0.4142 - val_acc: 0.8124\n",
      "Epoch 6/20\n",
      "182/182 [==============================] - 4s 20ms/step - loss: 0.4829 - acc: 0.7904 - val_loss: 0.4543 - val_acc: 0.8206\n",
      "Epoch 7/20\n",
      "182/182 [==============================] - 4s 20ms/step - loss: 0.4964 - acc: 0.7938 - val_loss: 0.4986 - val_acc: 0.7588\n",
      "Epoch 8/20\n",
      "182/182 [==============================] - 4s 19ms/step - loss: 0.4613 - acc: 0.8048 - val_loss: 0.4105 - val_acc: 0.8165\n",
      "Epoch 9/20\n",
      "182/182 [==============================] - 4s 21ms/step - loss: 0.4545 - acc: 0.8165 - val_loss: 0.3762 - val_acc: 0.8412\n",
      "Epoch 10/20\n",
      "182/182 [==============================] - 4s 19ms/step - loss: 0.4551 - acc: 0.8199 - val_loss: 0.4546 - val_acc: 0.7938\n",
      "Epoch 11/20\n",
      "182/182 [==============================] - 4s 22ms/step - loss: 0.4539 - acc: 0.8179 - val_loss: 0.4168 - val_acc: 0.8392\n",
      "Epoch 12/20\n",
      "182/182 [==============================] - 4s 20ms/step - loss: 0.5010 - acc: 0.7993 - val_loss: 0.4064 - val_acc: 0.8495\n",
      "Epoch 13/20\n",
      "182/182 [==============================] - 4s 20ms/step - loss: 0.5067 - acc: 0.7856 - val_loss: 0.4129 - val_acc: 0.8598\n",
      "Epoch 14/20\n",
      "182/182 [==============================] - 4s 20ms/step - loss: 0.4496 - acc: 0.8247 - val_loss: 0.3554 - val_acc: 0.8742\n",
      "Epoch 15/20\n",
      "182/182 [==============================] - 4s 20ms/step - loss: 0.4605 - acc: 0.8117 - val_loss: 0.3784 - val_acc: 0.8763\n",
      "Epoch 16/20\n",
      "182/182 [==============================] - 4s 20ms/step - loss: 0.4573 - acc: 0.8213 - val_loss: 0.3678 - val_acc: 0.8330\n",
      "Epoch 17/20\n",
      "182/182 [==============================] - 3s 19ms/step - loss: 0.4763 - acc: 0.8027 - val_loss: 0.4448 - val_acc: 0.8515\n",
      "Epoch 18/20\n",
      "182/182 [==============================] - 4s 21ms/step - loss: 0.4438 - acc: 0.8337 - val_loss: 0.4458 - val_acc: 0.8227\n",
      "Epoch 19/20\n",
      "182/182 [==============================] - 4s 20ms/step - loss: 0.4583 - acc: 0.8151 - val_loss: 0.4053 - val_acc: 0.8454\n",
      "Epoch 20/20\n",
      "182/182 [==============================] - 4s 20ms/step - loss: 0.4400 - acc: 0.8186 - val_loss: 0.5092 - val_acc: 0.7093\n"
     ]
    }
   ],
   "source": [
    "classification_model = create_model()\n",
    "\n",
    "history = classification_model.fit(\n",
    "    X_train_tokens_padded, \n",
    "    y_train,\n",
    "    batch_size=8,\n",
    "    epochs=20,\n",
    "    validation_data=(X_test_tokens_padded, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b5f8868",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def anticp_proba(sequence):\n",
    "    tokens = tokenizer.texts_to_sequences([sequence])\n",
    "    padded = keras.preprocessing.sequence.pad_sequences(tokens, maxlen=max_len)\n",
    "    return classification_model.predict(padded, verbose=0)[0][0]\n",
    "\n",
    "def mutate(sequence, factor=0.01, iterations=1_000):\n",
    "    initial_prob =  anticp_proba(sequence)\n",
    "    aas = 'ACDEFGHIKLMNPQRSTVWY.'\n",
    "    for iteration in range(iterations):\n",
    "        current_prob =  anticp_proba(sequence)\n",
    "        sequence_aas = list(sequence)\n",
    "        mutation_idx = random.randrange(0, len(sequence))\n",
    "        sequence_aas[mutation_idx] = random.choice(aas)\n",
    "        new_sequence = ''.join([aa for aa in sequence_aas if aa in aas]).split('.')[0] + '.'\n",
    "        if new_sequence == '.':\n",
    "            continue\n",
    "        new_prob     = anticp_proba(new_sequence)\n",
    "        if new_prob > current_prob:\n",
    "            print(f'>mutated_{iteration}:{new_prob}', new_sequence.replace('.',''), sep='\\n')\n",
    "            sequence = new_sequence\n",
    "        elif random.random() < factor:\n",
    "            sequence = new_sequence\n",
    "    return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5ee5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutate('LLGDFFRKSKEKIGKEFKRIVQRIKDFLRNLVPRTES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c968da0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">original\n",
      "LLGDFFRKSKEKIGKEFKRIVQRIKDFLRNLVPRTES\n",
      ">mutated_104:0.8197231888771057\n",
      "LLGDFFRKSK\n",
      ">mutated_105:0.8428837656974792\n",
      "LLGDFFRKHK\n",
      ">mutated_107:0.8791126608848572\n",
      "LLGAFFRKHK\n",
      ">mutated_111:0.8816781640052795\n",
      "FLGAFFRKHK\n",
      ">mutated_113:0.8817476034164429\n",
      "FLGAFFMKHK\n",
      ">mutated_115:0.9175047874450684\n",
      "FLGAFFKKHK\n",
      ">mutated_118:0.9304203391075134\n",
      "FLHAFFKKHK\n",
      ">mutated_122:0.9436076283454895\n",
      "FLHAFFKKHKH\n",
      ">mutated_129:0.9498093724250793\n",
      "FLHKFFKKHKH\n",
      ">mutated_139:0.9543346166610718\n",
      "FLHKFFKKHKK\n",
      ">mutated_148:0.9619104266166687\n",
      "FLHKFFKKCKK\n",
      ">mutated_150:0.9667935967445374\n",
      "FLHKFFKKCKKL\n",
      ">mutated_152:0.9717153310775757\n",
      "FLHKFWKKCKKL\n",
      ">mutated_154:0.9735897183418274\n",
      "FDHKFWKKCKKL\n",
      ">mutated_157:0.974625289440155\n",
      "FDHKKWKKCKKL\n",
      ">mutated_179:0.9755672216415405\n",
      "FDIKKWKKCKKL\n",
      ">mutated_189:0.978655219078064\n",
      "FDIWKWKKCKKL\n",
      ">mutated_195:0.9800183176994324\n",
      "FDWWKWKKCKKL\n",
      ">mutated_240:0.9803245067596436\n",
      "FDWWKWKKKKKL\n",
      ">mutated_244:0.9829104542732239\n",
      "FDWWKWKKKKKK\n",
      ">mutated_268:0.9848653078079224\n",
      "FDWWWWKKKKKK\n",
      ">mutated_337:0.9851222038269043\n",
      "FDWWWWKKKKCK\n",
      ">mutated_386:0.9854491353034973\n",
      "FDWWWWWKKKCK\n",
      ">mutated_441:0.9825960993766785\n",
      "FDWWWWWKKKCA\n",
      ">mutated_442:0.9833744764328003\n",
      "FDWWWWWKKKCL\n",
      ">mutated_454:0.9835175275802612\n",
      "FDWWWWWKKCCL\n",
      ">mutated_535:0.9857520461082458\n",
      "FDWWWWWKKCCC\n",
      ">mutated_586:0.9813377261161804\n",
      "FDDWWWWKKCCCP\n",
      ">mutated_599:0.9815359115600586\n",
      "FDDWWWWKKCCCG\n",
      ">mutated_609:0.9817122220993042\n",
      "FDDWWWWKKCCCI\n",
      ">mutated_651:0.9846735596656799\n",
      "FDDWWWWKKCCCC\n",
      ">mutated_663:0.9819322824478149\n",
      "FADWWWWKKCCLC\n",
      ">mutated_668:0.981938362121582\n",
      "AADWWWWKKCCLC\n",
      ">mutated_687:0.9855005741119385\n",
      "AADWWWWKKCCCC\n",
      ">mutated_703:0.985735297203064\n",
      "AFDWWWWKKCCCC\n",
      ">mutated_734:0.9858851432800293\n",
      "AFDWWWWKWCCCC\n",
      ">mutated_745:0.9858923554420471\n",
      "FFDWWWWKWCCCC\n",
      ">mutated_784:0.986933171749115\n",
      "CFDWWWWKWCCCC\n",
      ">mutated_841:0.9776765704154968\n",
      "CFDWWQWKWCCCC\n",
      ">mutated_843:0.978299617767334\n",
      "CFDWWQWWWCCCC\n",
      ">mutated_844:0.9791930913925171\n",
      "CFDWWDWWWCCCC\n",
      ">mutated_845:0.98601895570755\n",
      "CFDWWCWWWCCCC\n",
      ">mutated_875:0.9829235076904297\n",
      "CFDWHCWWWCCCC\n",
      ">mutated_963:0.9840968251228333\n",
      "CFDWKCWWWCCCC\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'CFDWKCWWWCCCC.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = 'LLGDFFRKSKEKIGKEFKRIVQRIKDFLRNLVPRTES'\n",
    "\n",
    "print('>original\\n'+sequence)\n",
    "halucinate(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9efd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hallucinated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05b995a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
